"""
æµ‹è¯•RAGç³»ç»ŸåŠŸèƒ½
"""

import asyncio
import os
from datetime import datetime
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

# æ¨¡æ‹ŸAzure OpenAIå“åº”ï¼ˆæµ‹è¯•ç¯å¢ƒï¼‰
class MockAzureOpenAI:
    """æ¨¡æ‹ŸAzure OpenAIå®¢æˆ·ç«¯"""
    
    class Embeddings:
        async def create(self, model, input):
            # æ¨¡æ‹Ÿå‘é‡ç”Ÿæˆ
            if isinstance(input, list):
                embeddings = []
                for text in input:
                    # ç®€å•çš„å“ˆå¸Œæ¨¡æ‹Ÿ
                    hash_val = hash(text)
                    embedding = [(hash_val >> i) & 1 for i in range(1536)]
                    embeddings.append(type('obj', (object,), {'embedding': embedding}))
                return type('obj', (object,), {'data': embeddings})
            else:
                hash_val = hash(input)
                embedding = [(hash_val >> i) & 1 for i in range(1536)]
                return type('obj', (object,), {
                    'data': [type('obj', (object,), {'embedding': embedding})]
                })
    
    class Chat:
        class Completions:
            async def create(self, model, messages, temperature=0.7, max_tokens=500):
                # æ ¹æ®è¾“å…¥ç”Ÿæˆå›å¤
                user_input = messages[-1]['content']
                if "ä½ å¥½" in user_input:
                    content = "ä½ å¥½å‘€ï¼ä»Šå¤©è¿‡å¾—æ€ä¹ˆæ ·ï¼ŸğŸ˜Š"
                elif "å¤©æ°”" in user_input:
                    content = "ä»Šå¤©å¤©æ°”çœŸä¸é”™å‘¢ï¼è¦ä¸è¦å‡ºå»èµ°èµ°ï¼Ÿ"
                else:
                    content = "å—¯å—¯ï¼Œæˆ‘æ˜ç™½ä½ çš„æ„æ€ï½"
                
                return type('obj', (object,), {
                    'choices': [type('obj', (object,), {
                        'message': type('obj', (object,), {'content': content})
                    })]
                })
        
        def __init__(self):
            self.completions = self.Completions()
    
    def __init__(self, **kwargs):
        self.embeddings = self.Embeddings()
        self.chat = self.Chat()


class AsyncAzureOpenAI(MockAzureOpenAI):
    """å¼‚æ­¥ç‰ˆæœ¬çš„æ¨¡æ‹Ÿå®¢æˆ·ç«¯"""
    pass


# æ¨¡æ‹ŸRAGæœåŠ¡
class SimpleRAGService:
    """ç®€åŒ–çš„RAGæœåŠ¡ï¼ˆä¸ä¾èµ–æ•°æ®åº“ï¼‰"""
    
    def __init__(self):
        self.client = AsyncAzureOpenAI()
        self.embedding_deployment = "text-embedding-ada-002"
        self.chat_deployment = "gpt-35-turbo"
    
    async def generate_embedding(self, text: str):
        """ç”Ÿæˆæ–‡æœ¬å‘é‡"""
        response = await self.client.embeddings.create(
            model=self.embedding_deployment,
            input=text
        )
        return response.data[0].embedding
    
    async def batch_generate_embeddings(self, texts):
        """æ‰¹é‡ç”Ÿæˆå‘é‡"""
        if not texts:
            return []
        
        batch_size = 16
        all_embeddings = []
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            response = await self.client.embeddings.create(
                model=self.embedding_deployment,
                input=batch
            )
            embeddings = [item.embedding for item in response.data]
            all_embeddings.extend(embeddings)
        
        return all_embeddings
    
    async def generate_response(self, user_input: str, persona_name: str = "å°æ˜"):
        """ç”Ÿæˆå›å¤"""
        system_prompt = f"""ä½ æ˜¯{persona_name}ï¼Œä¸€ä¸ªå‹å–„ã€å¹½é»˜çš„æœ‹å‹ã€‚
ä½ å–œæ¬¢ä½¿ç”¨è¡¨æƒ…ç¬¦å·ï¼Œè¯´è¯æ¯”è¾ƒéšæ€§è‡ªç„¶ã€‚"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_input}
        ]
        
        response = await self.client.chat.completions.create(
            model=self.chat_deployment,
            messages=messages,
            temperature=0.7,
            max_tokens=500
        )
        
        return response.choices[0].message.content
    
    def analyze_conversation_patterns(self, messages):
        """åˆ†æå¯¹è¯æ¨¡å¼"""
        if not messages:
            return {}
        
        # åˆ†æå¹³å‡é•¿åº¦
        total_length = sum(len(msg['content']) for msg in messages)
        avg_length = total_length / len(messages) if messages else 0
        
        # åˆ†ææƒ…æ„Ÿ
        positive_count = sum(1 for msg in messages if any(
            word in msg['content'] for word in ["å¥½", "å¼€å¿ƒ", "å“ˆå“ˆ", "ğŸ˜Š"]
        ))
        
        return {
            "response_patterns": {
                "average_message_length": avg_length,
                "message_count": len(messages)
            },
            "emotional_patterns": {
                "positive": positive_count / len(messages) if messages else 0,
                "neutral": 1 - (positive_count / len(messages) if messages else 0)
            }
        }


async def test_rag_functions():
    """æµ‹è¯•RAGåŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•RAGç³»ç»ŸåŠŸèƒ½\n")
    
    rag = SimpleRAGService()
    
    # 1. æµ‹è¯•å‘é‡ç”Ÿæˆ
    print("1ï¸âƒ£ æµ‹è¯•å‘é‡ç”Ÿæˆ")
    text = "ä»Šå¤©å¤©æ°”çœŸå¥½ï¼Œè¦ä¸è¦ä¸€èµ·å»å…¬å›­èµ°èµ°ï¼Ÿ"
    embedding = await rag.generate_embedding(text)
    print(f"âœ… ç”Ÿæˆå‘é‡é•¿åº¦: {len(embedding)}")
    print(f"   å‘é‡å‰10ç»´: {embedding[:10]}")
    
    # 2. æµ‹è¯•æ‰¹é‡å‘é‡ç”Ÿæˆ
    print("\n2ï¸âƒ£ æµ‹è¯•æ‰¹é‡å‘é‡ç”Ÿæˆ")
    texts = [
        "æ—©ä¸Šå¥½ï¼",
        "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
        "ä¸€èµ·å»åƒé¥­å§",
        "å‘¨æœ«æœ‰ä»€ä¹ˆè®¡åˆ’å—ï¼Ÿ"
    ]
    embeddings = await rag.batch_generate_embeddings(texts)
    print(f"âœ… ç”Ÿæˆäº† {len(embeddings)} ä¸ªå‘é‡")
    
    # 3. æµ‹è¯•å¯¹è¯ç”Ÿæˆ
    print("\n3ï¸âƒ£ æµ‹è¯•å¯¹è¯ç”Ÿæˆ")
    test_inputs = [
        "ä½ å¥½ï¼",
        "ä»Šå¤©å¤©æ°”çœŸä¸é”™",
        "å‘¨æœ«æƒ³å»å“ªé‡Œç©ï¼Ÿ"
    ]
    
    for user_input in test_inputs:
        response = await rag.generate_response(user_input, "å°çº¢")
        print(f"ğŸ‘¤ ç”¨æˆ·: {user_input}")
        print(f"ğŸ¤– å°çº¢: {response}")
        print()
    
    # 4. æµ‹è¯•å¯¹è¯æ¨¡å¼åˆ†æ
    print("4ï¸âƒ£ æµ‹è¯•å¯¹è¯æ¨¡å¼åˆ†æ")
    test_messages = [
        {"content": "æ—©ä¸Šå¥½ï¼ä»Šå¤©çœŸå¼€å¿ƒ", "sender": "å°æ˜", "timestamp": datetime.now()},
        {"content": "å“ˆå“ˆï¼Œæ˜¯å•Š", "sender": "å°çº¢", "timestamp": datetime.now()},
        {"content": "ä¸€èµ·å»åƒé¥­å§ğŸ˜Š", "sender": "å°æ˜", "timestamp": datetime.now()},
        {"content": "å¥½å•Šå¥½å•Šï¼", "sender": "å°çº¢", "timestamp": datetime.now()},
    ]
    
    patterns = rag.analyze_conversation_patterns(test_messages)
    print(f"âœ… åˆ†æç»“æœ:")
    print(f"   å¹³å‡æ¶ˆæ¯é•¿åº¦: {patterns['response_patterns']['average_message_length']:.1f}")
    print(f"   ç§¯ææƒ…ç»ªæ¯”ä¾‹: {patterns['emotional_patterns']['positive']:.1%}")
    
    print("\nâœ¨ RAGç³»ç»Ÿæµ‹è¯•å®Œæˆï¼")


async def test_hybrid_search():
    """æµ‹è¯•æ··åˆæœç´¢åŠŸèƒ½"""
    print("\n5ï¸âƒ£ æµ‹è¯•æ··åˆæœç´¢é€»è¾‘")
    
    # æ¨¡æ‹Ÿæ¶ˆæ¯æ•°æ®
    messages = [
        {"content": "ä»Šå¤©å»å…¬å›­æ•£æ­¥äº†", "timestamp": "2024-01-01 10:00"},
        {"content": "å…¬å›­é‡Œçš„èŠ±å¼€å¾—çœŸæ¼‚äº®", "timestamp": "2024-01-01 10:05"},
        {"content": "æ™šä¸Šä¸€èµ·åƒé¥­å—ï¼Ÿ", "timestamp": "2024-01-01 18:00"},
        {"content": "å¥½å•Šï¼Œå»å“ªé‡Œåƒï¼Ÿ", "timestamp": "2024-01-01 18:02"},
    ]
    
    # æ¨¡æ‹Ÿæœç´¢
    query = "å…¬å›­"
    matched = [msg for msg in messages if query in msg['content']]
    print(f"âœ… æœç´¢ '{query}' æ‰¾åˆ° {len(matched)} æ¡ç›¸å…³æ¶ˆæ¯:")
    for msg in matched:
        print(f"   - {msg['content']}")


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_rag_functions())
    asyncio.run(test_hybrid_search())