#!/usr/bin/env python3
"""
æ£€æŸ¥å’Œé…ç½®å‘é‡ï¼ˆembeddingsï¼‰æœåŠ¡
"""
import os
import sys
from pathlib import Path
import asyncio
from typing import List

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from backend.core.config import settings
from backend.services.rag_service import RAGService
from backend.core.database import motor_client, init_db


async def check_current_config():
    """æ£€æŸ¥å½“å‰é…ç½®"""
    print("ğŸ” å½“å‰å‘é‡æœåŠ¡é…ç½®:")
    print("=" * 50)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    use_mock = getattr(settings, "USE_MOCK_EMBEDDINGS", "false").lower() == "true"
    print(f"USE_MOCK_EMBEDDINGS: {use_mock}")
    
    if not use_mock:
        print("\nâœ… ä½¿ç”¨çœŸå®çš„Azure OpenAI Embeddings")
        print(f"   ç«¯ç‚¹: {settings.AZURE_OPENAI_ENDPOINT[:30]}...")
        print(f"   APIå¯†é’¥: {'å·²è®¾ç½®' if settings.AZURE_OPENAI_KEY else 'âŒ æœªè®¾ç½®'}")
        print(f"   Embeddingæ¨¡å‹éƒ¨ç½²: {settings.AZURE_OPENAI_EMBEDDING_DEPLOYMENT}")
        print(f"   APIç‰ˆæœ¬: {settings.AZURE_OPENAI_API_VERSION}")
    else:
        print("\nâš ï¸  ä½¿ç”¨Mock Embeddingsï¼ˆä»¿çœŸæ¨¡å¼ï¼‰")
        print("   è¿™ä¼šå½±å“æœç´¢è´¨é‡ï¼Œå»ºè®®åˆ‡æ¢åˆ°çœŸå®æœåŠ¡")
    
    return use_mock


async def test_embedding_generation():
    """æµ‹è¯•å‘é‡ç”Ÿæˆ"""
    print("\nğŸ§ª æµ‹è¯•å‘é‡ç”Ÿæˆ...")
    print("=" * 50)
    
    try:
        # åˆå§‹åŒ–æ•°æ®åº“
        await init_db()
        
        # åˆ›å»ºRAGæœåŠ¡
        rag_service = RAGService()
        
        # æµ‹è¯•æ–‡æœ¬
        test_texts = [
            "Hello, how are you today?",
            "ä»Šå¤©å¤©æ°”çœŸä¸é”™",
            "æˆ‘å–œæ¬¢ç¼–ç¨‹"
        ]
        
        print(f"æµ‹è¯•æ–‡æœ¬æ•°é‡: {len(test_texts)}")
        
        # ç”Ÿæˆå‘é‡
        embeddings = await rag_service.generate_embeddings(test_texts)
        
        if embeddings and len(embeddings) == len(test_texts):
            print(f"âœ… æˆåŠŸç”Ÿæˆ {len(embeddings)} ä¸ªå‘é‡")
            print(f"   å‘é‡ç»´åº¦: {len(embeddings[0])}")
            print(f"   å‘é‡ç±»å‹: {type(embeddings[0][0])}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯mockå‘é‡
            if all(isinstance(e, (int, float)) and e == embeddings[0][0] for emb in embeddings for e in emb[:10]):
                print("   âš ï¸  æ£€æµ‹åˆ°Mockå‘é‡ï¼ˆæ‰€æœ‰å€¼ç›¸åŒï¼‰")
            else:
                print("   âœ… çœŸå®å‘é‡ï¼ˆå€¼æœ‰å˜åŒ–ï¼‰")
            
            return True
        else:
            print(f"âŒ å‘é‡ç”Ÿæˆå¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False
    finally:
        # å…³é—­æ•°æ®åº“è¿æ¥
        if motor_client:
            motor_client.close()


async def test_vector_search():
    """æµ‹è¯•å‘é‡æœç´¢"""
    print("\nğŸ” æµ‹è¯•å‘é‡æœç´¢...")
    print("=" * 50)
    
    try:
        # åˆå§‹åŒ–æ•°æ®åº“
        await init_db()
        
        # åˆ›å»ºRAGæœåŠ¡
        rag_service = RAGService()
        
        # æµ‹è¯•æ•°æ®
        from backend.models.message import Message
        from datetime import datetime
        
        test_persona_id = "test_persona_123"
        messages = [
            Message(
                persona_id=test_persona_id,
                sender="Alice",
                content="I love programming in Python",
                timestamp=datetime.now()
            ),
            Message(
                persona_id=test_persona_id,
                sender="Bob",
                content="Python is great for data science",
                timestamp=datetime.now()
            ),
            Message(
                persona_id=test_persona_id,
                sender="Alice",
                content="Let's go for a walk in the park",
                timestamp=datetime.now()
            )
        ]
        
        # ç”Ÿæˆå¹¶å­˜å‚¨å‘é‡
        print("å­˜å‚¨æµ‹è¯•æ¶ˆæ¯...")
        texts = [m.content for m in messages]
        embeddings = await rag_service.generate_embeddings(texts)
        
        # æ¨¡æ‹Ÿå­˜å‚¨ï¼ˆå®é™…åº”è¯¥å­˜åˆ°æ•°æ®åº“ï¼‰
        for msg, emb in zip(messages, embeddings):
            msg.embedding = emb
        
        # æµ‹è¯•æœç´¢
        query = "Python programming"
        print(f"æœç´¢æŸ¥è¯¢: '{query}'")
        
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = await rag_service.generate_embedding(query)
        
        # è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆç®€å•çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        def cosine_similarity(a: List[float], b: List[float]) -> float:
            dot_product = sum(x * y for x, y in zip(a, b))
            norm_a = sum(x * x for x in a) ** 0.5
            norm_b = sum(y * y for y in b) ** 0.5
            return dot_product / (norm_a * norm_b) if norm_a * norm_b > 0 else 0
        
        results = []
        for msg in messages:
            score = cosine_similarity(query_embedding, msg.embedding)
            results.append((msg, score))
        
        # æ’åºç»“æœ
        results.sort(key=lambda x: x[1], reverse=True)
        
        print("\næœç´¢ç»“æœ:")
        for msg, score in results:
            print(f"   ç›¸ä¼¼åº¦ {score:.4f}: {msg.content}")
        
        # æ£€æŸ¥ç»“æœè´¨é‡
        if results[0][1] > results[-1][1]:
            print("\nâœ… å‘é‡æœç´¢å·¥ä½œæ­£å¸¸ï¼ˆç›¸ä¼¼åº¦æœ‰å·®å¼‚ï¼‰")
        else:
            print("\nâš ï¸  å‘é‡æœç´¢å¯èƒ½ä½¿ç”¨Mockï¼ˆç›¸ä¼¼åº¦ç›¸åŒï¼‰")
        
        return True
        
    except Exception as e:
        print(f"âŒ æœç´¢æµ‹è¯•å¤±è´¥: {e}")
        return False
    finally:
        if motor_client:
            motor_client.close()


def show_configuration_guide():
    """æ˜¾ç¤ºé…ç½®æŒ‡å—"""
    print("\nğŸ“š å¦‚ä½•é…ç½®çœŸå®çš„å‘é‡æœåŠ¡:")
    print("=" * 50)
    print("""
1. åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®ï¼ˆå¦‚æœè¿˜æ²¡æœ‰.envï¼Œå¤åˆ¶.env.exampleï¼‰:
   
   # å…³é—­Mockæ¨¡å¼
   USE_MOCK_EMBEDDINGS=false
   
   # Azure OpenAIé…ç½®
   AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
   AZURE_OPENAI_KEY=your-api-key
   AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-ada-002

2. ç¡®ä¿Azure OpenAIèµ„æºå·²éƒ¨ç½²embeddingæ¨¡å‹

3. é‡å¯åç«¯æœåŠ¡:
   ./stop_services.sh
   ./start_services.sh

4. å†æ¬¡è¿è¡Œæ­¤è„šæœ¬éªŒè¯é…ç½®
""")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Second Self å‘é‡æœåŠ¡æ£€æŸ¥å·¥å…·")
    print("=" * 50)
    
    # 1. æ£€æŸ¥å½“å‰é…ç½®
    is_mock = await check_current_config()
    
    # 2. æµ‹è¯•å‘é‡ç”Ÿæˆ
    embedding_ok = await test_embedding_generation()
    
    # 3. æµ‹è¯•å‘é‡æœç´¢
    if embedding_ok:
        search_ok = await test_vector_search()
    else:
        search_ok = False
    
    # 4. æ€»ç»“å’Œå»ºè®®
    print("\nğŸ“Š æ£€æŸ¥ç»“æœ:")
    print("=" * 50)
    
    if is_mock:
        print("âŒ å½“å‰ä½¿ç”¨Mockå‘é‡æœåŠ¡")
        print("   - æœç´¢åŠŸèƒ½å—é™")
        print("   - å»ºè®®é…ç½®çœŸå®çš„Azure OpenAIæœåŠ¡")
        show_configuration_guide()
    else:
        if embedding_ok and search_ok:
            print("âœ… å‘é‡æœåŠ¡å·¥ä½œæ­£å¸¸ï¼")
            print("   - Azure OpenAIé…ç½®æ­£ç¡®")
            print("   - å‘é‡ç”Ÿæˆå’Œæœç´¢åŠŸèƒ½æ­£å¸¸")
        else:
            print("âš ï¸  Azure OpenAIé…ç½®å¯èƒ½æœ‰é—®é¢˜")
            print("   - è¯·æ£€æŸ¥APIå¯†é’¥å’Œç«¯ç‚¹")
            print("   - ç¡®ä¿éƒ¨ç½²äº†embeddingæ¨¡å‹")
            show_configuration_guide()


if __name__ == "__main__":
    asyncio.run(main())