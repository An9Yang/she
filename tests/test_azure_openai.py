"""
æµ‹è¯•Azure OpenAIè¿æ¥
"""

import asyncio
import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv("backend/.env")

async def test_azure_openai():
    """æµ‹è¯•Azure OpenAI APIè¿æ¥"""
    print("ğŸ”§ æµ‹è¯•Azure OpenAIè¿æ¥...\n")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
    api_key = os.getenv("AZURE_OPENAI_KEY")
    chat_deployment = os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT")
    api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2025-01-01-preview")
    
    print(f"ğŸ“ Endpoint: {endpoint}")
    print(f"ğŸš€ Chat Deployment: {chat_deployment}")
    print(f"ğŸ“… API Version: {api_version}")
    print()
    
    if not all([endpoint, api_key, chat_deployment]):
        print("âŒ ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡")
        return False
    
    try:
        from openai import AsyncAzureOpenAI
        
        # åˆ›å»ºå®¢æˆ·ç«¯
        client = AsyncAzureOpenAI(
            azure_endpoint=endpoint,
            api_key=api_key,
            api_version=api_version
        )
        
        print("âœ… å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•èŠå¤©åŠŸèƒ½
        print("\nğŸ¤– æµ‹è¯•èŠå¤©ç”Ÿæˆ...")
        response = await client.chat.completions.create(
            model=chat_deployment,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹"},
                {"role": "user", "content": "ä½ å¥½ï¼è¯·ç”¨ä¸€å¥è¯ä»‹ç»è‡ªå·±ã€‚"}
            ],
            max_tokens=100
        )
        
        print(f"âœ… å›å¤: {response.choices[0].message.content}")
        
        # æµ‹è¯•å‘é‡ç”Ÿæˆï¼ˆå¦‚æœæœ‰embeddingæ¨¡å‹ï¼‰
        embedding_deployment = os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT")
        if embedding_deployment and embedding_deployment != "text-embedding-ada-002":
            print("\nğŸ”¢ æµ‹è¯•å‘é‡ç”Ÿæˆ...")
            try:
                embedding_response = await client.embeddings.create(
                    model=embedding_deployment,
                    input="æµ‹è¯•æ–‡æœ¬"
                )
                print(f"âœ… å‘é‡ç»´åº¦: {len(embedding_response.data[0].embedding)}")
            except Exception as e:
                print(f"âš ï¸  å‘é‡ç”Ÿæˆå¤±è´¥ï¼ˆå¯èƒ½è¯¥éƒ¨ç½²ä¸æ”¯æŒï¼‰: {e}")
        
        print("\nâœ¨ Azure OpenAI è¿æ¥æµ‹è¯•æˆåŠŸï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ è¿æ¥å¤±è´¥: {e}")
        print("\nå¯èƒ½çš„åŸå› ï¼š")
        print("1. APIå¯†é’¥æ— æ•ˆ")
        print("2. ç«¯ç‚¹URLé”™è¯¯")
        print("3. éƒ¨ç½²åç§°é”™è¯¯")
        print("4. ç½‘ç»œè¿æ¥é—®é¢˜")
        return False


async def test_simple_rag():
    """æµ‹è¯•ç®€å•çš„RAGåŠŸèƒ½"""
    print("\n\nğŸ§ª æµ‹è¯•RAGåŠŸèƒ½...\n")
    
    try:
        from backend.services.rag_service import RAGService
        
        rag = RAGService()
        
        # æµ‹è¯•æ–‡æœ¬å‘é‡ç”Ÿæˆ
        print("1ï¸âƒ£ æµ‹è¯•æ–‡æœ¬å‘é‡ç”Ÿæˆ...")
        embedding = await rag.generate_embedding("ä»Šå¤©å¤©æ°”çœŸå¥½")
        print(f"âœ… ç”Ÿæˆå‘é‡é•¿åº¦: {len(embedding)}")
        
        # æµ‹è¯•å¯¹è¯ç”Ÿæˆ
        print("\n2ï¸âƒ£ æµ‹è¯•å¯¹è¯ç”Ÿæˆ...")
        response = await rag.generate_response(
            persona_id="test123",
            user_input="ä½ å¥½ï¼Œæœ€è¿‘æ€ä¹ˆæ ·ï¼Ÿ",
            context_messages=[],
            chat_history=[]
        )
        print(f"âœ… ç”Ÿæˆå›å¤: {response}")
        
        print("\nâœ¨ RAGåŠŸèƒ½æµ‹è¯•æˆåŠŸï¼")
        return True
        
    except Exception as e:
        print(f"âŒ RAGæµ‹è¯•å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    print("=" * 60)
    print("ğŸš€ Second Self - Azure OpenAI è¿æ¥æµ‹è¯•")
    print("=" * 60)
    
    # è¿è¡Œæµ‹è¯•
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    # æµ‹è¯•Azure OpenAI
    openai_ok = loop.run_until_complete(test_azure_openai())
    
    # å¦‚æœOpenAIè¿æ¥æˆåŠŸï¼Œæµ‹è¯•RAG
    if openai_ok:
        loop.run_until_complete(test_simple_rag())
    
    print("\n" + "=" * 60)