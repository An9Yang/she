"""
RAGæœåŠ¡å®ç°
"""

from typing import List, Dict, Optional, Any
from datetime import datetime
import asyncio
from beanie import PydanticObjectId
from openai import AsyncAzureOpenAI
import numpy as np
from backend.core.config import settings
from backend.models.message import Message
from backend.models.persona import Persona
from backend.models.chat import ChatHistory
from backend.core.logger import logger
from backend.services.mock_embeddings import MockEmbeddingService


class RAGService:
    """æ··åˆRAGæœåŠ¡"""
    
    def __init__(self):
        """åˆå§‹åŒ–RAGæœåŠ¡"""
        self.client = AsyncAzureOpenAI(
            azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
            api_key=settings.AZURE_OPENAI_KEY,
            api_version=getattr(settings, "AZURE_OPENAI_API_VERSION", "2025-01-01-preview")
        )
        self.embedding_deployment = settings.AZURE_OPENAI_EMBEDDING_DEPLOYMENT
        self.chat_deployment = settings.AZURE_OPENAI_CHAT_DEPLOYMENT
        
    async def generate_embedding(self, text: str) -> List[float]:
        """ç”Ÿæˆæ–‡æœ¬å‘é‡"""
        try:
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨æ¨¡æ‹Ÿembeddings
            use_mock = getattr(settings, "USE_MOCK_EMBEDDINGS", "false").lower() == "true"
            
            if use_mock:
                logger.info("ä½¿ç”¨æ¨¡æ‹ŸembeddingæœåŠ¡")
                return MockEmbeddingService.generate_embedding(text)
            else:
                logger.info("ä½¿ç”¨Azure OpenAI embeddingæœåŠ¡")
                response = await self.client.embeddings.create(
                    model=self.embedding_deployment,
                    input=text
                )
                return response.data[0].embedding
        except Exception as e:
            logger.error(f"ç”Ÿæˆå‘é‡å¤±è´¥: {str(e)}")
            # å¦‚æœAzureå¤±è´¥ï¼Œé™çº§åˆ°æ¨¡æ‹ŸæœåŠ¡
            logger.warning("Azure OpenAIå¤±è´¥ï¼Œé™çº§åˆ°æ¨¡æ‹ŸembeddingæœåŠ¡")
            return MockEmbeddingService.generate_embedding(text)
    
    async def batch_generate_embeddings(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡ç”Ÿæˆå‘é‡"""
        if not texts:
            return []
            
        try:
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨æ¨¡æ‹Ÿembeddings
            use_mock = getattr(settings, "USE_MOCK_EMBEDDINGS", "false").lower() == "true"
            
            if use_mock:
                logger.info("ä½¿ç”¨æ¨¡æ‹ŸembeddingsæœåŠ¡")
                return MockEmbeddingService.generate_embeddings(texts)
            else:
                logger.info(f"ä½¿ç”¨Azure OpenAIæ‰¹é‡ç”Ÿæˆ{len(texts)}ä¸ªembeddings")
                # Azure OpenAIé™åˆ¶æ¯æ¬¡è¯·æ±‚æœ€å¤š16ä¸ªæ–‡æœ¬
                batch_size = 16
                all_embeddings = []
                
                for i in range(0, len(texts), batch_size):
                    batch = texts[i:i + batch_size]
                    response = await self.client.embeddings.create(
                        model=self.embedding_deployment,
                        input=batch
                    )
                    embeddings = [item.embedding for item in response.data]
                    all_embeddings.extend(embeddings)
                    
                return all_embeddings
        except Exception as e:
            logger.error(f"æ‰¹é‡ç”Ÿæˆå‘é‡å¤±è´¥: {str(e)}")
            # å¦‚æœAzureå¤±è´¥ï¼Œé™çº§åˆ°æ¨¡æ‹ŸæœåŠ¡
            logger.warning("Azure OpenAIå¤±è´¥ï¼Œé™çº§åˆ°æ¨¡æ‹ŸembeddingsæœåŠ¡")
            return MockEmbeddingService.generate_embeddings(texts)
    
    async def hybrid_search(
        self, 
        persona_id: str,
        query: str,
        limit: int = 10,
        time_range: Optional[Dict[str, datetime]] = None
    ) -> List[Message]:
        """æ··åˆæ£€ç´¢ - ç®€åŒ–ç‰ˆæœ¬"""
        try:
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            query_filter = {
                "persona_id": PydanticObjectId(persona_id),
                "$or": [
                    {"content": {"$regex": query, "$options": "i"}},  # å†…å®¹åŒ¹é…
                    {"sender": {"$regex": query, "$options": "i"}}    # å‘é€è€…åŒ¹é…
                ]
            }
            
            # æ—¶é—´èŒƒå›´è¿‡æ»¤
            if time_range:
                time_filter = {}
                if "start" in time_range:
                    time_filter["$gte"] = time_range["start"]
                if "end" in time_range:
                    time_filter["$lte"] = time_range["end"]
                if time_filter:
                    query_filter["timestamp"] = time_filter
            
            # æ‰§è¡ŒæŸ¥è¯¢
            messages = await Message.find(query_filter).limit(limit).to_list()
            
            return messages
            
        except Exception as e:
            logger.error(f"æ··åˆæœç´¢å¤±è´¥: {str(e)}")
            # é™çº§åˆ°ç®€å•æœç´¢
            return await Message.find(
                {"persona_id": PydanticObjectId(persona_id)}
            ).sort("-timestamp").limit(limit).to_list()
    
    async def generate_response(
        self,
        persona_id: str,
        user_input: str,
        context_messages: List[Message],
        chat_history: Optional[List[Dict[str, str]]] = None
    ) -> str:
        """ç”Ÿæˆå›å¤"""
        try:
            # è·å–äººæ ¼ä¿¡æ¯
            persona = await Persona.get(PydanticObjectId(persona_id))
            if not persona:
                raise ValueError("äººæ ¼ä¸å­˜åœ¨")
            
            # æ„å»ºç³»ç»Ÿæç¤º
            system_prompt = self._build_system_prompt(persona)
            
            # æ„å»ºä¸Šä¸‹æ–‡
            context = self._build_context(context_messages)
            
            # æ„å»ºæ¶ˆæ¯å†å²
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "system", "content": f"ç›¸å…³ä¸Šä¸‹æ–‡:\n{context}"}
            ]
            
            # æ·»åŠ èŠå¤©å†å²
            if chat_history:
                for msg in chat_history[-10:]:  # æœ€è¿‘10æ¡
                    messages.append({
                        "role": msg.get("role", "user"),
                        "content": msg.get("content", "")
                    })
            
            # æ·»åŠ ç”¨æˆ·è¾“å…¥
            messages.append({"role": "user", "content": user_input})
            
            # è°ƒç”¨Azure OpenAI
            # o3æ¨¡å‹ä½¿ç”¨max_completion_tokensè€Œä¸æ˜¯max_tokens
            # o3æ¨¡å‹ä¸æ”¯æŒtemperatureå‚æ•°ï¼Œåªèƒ½ç”¨é»˜è®¤å€¼1
            response = await self.client.chat.completions.create(
                model=self.chat_deployment,
                messages=messages,
                max_completion_tokens=500
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå›å¤å¤±è´¥: {str(e)}")
            raise
    
    def _build_system_prompt(self, persona: Persona) -> str:
        """æ„å»ºç³»ç»Ÿæç¤º"""
        prompt = f"""ä½ æ˜¯{persona.name}ï¼Œéœ€è¦æ¨¡æ‹Ÿtaçš„è¯´è¯é£æ ¼å’Œæ€§æ ¼ç‰¹ç‚¹ã€‚

åŸºæœ¬ä¿¡æ¯:
- æ˜µç§°: {persona.name}
- æ¶ˆæ¯æ•°é‡: {persona.message_count}
- æ´»è·ƒæ—¶é—´: {persona.created_at.strftime('%Yå¹´%mæœˆ')}å¼€å§‹

æ€§æ ¼ç‰¹å¾:
"""
        
        # æ·»åŠ æ€§æ ¼ç‰¹å¾
        if hasattr(persona, 'style_features') and persona.style_features:
            for trait, score in persona.style_features.items():
                if score > 0.7:
                    prompt += f"- {trait}: éå¸¸æ˜æ˜¾\n"
                elif score > 0.4:
                    prompt += f"- {trait}: æ¯”è¾ƒæ˜æ˜¾\n"
        
        # æ·»åŠ è¯´è¯é£æ ¼
        if hasattr(persona, 'sentence_patterns') and persona.sentence_patterns:
            prompt += f"\nè¯´è¯é£æ ¼:\n"
            if persona.emoji_profile and len(persona.emoji_profile) > 5:
                prompt += "- ç»å¸¸ä½¿ç”¨è¡¨æƒ…ç¬¦å·\n"
            if persona.sentence_patterns:
                prompt += f"- å¥å¼ç‰¹ç‚¹: {list(persona.sentence_patterns.keys())[:3]}\n"
            if persona.frequent_words:
                prompt += f"- å¸¸ç”¨è¯è¯­: {', '.join(persona.frequent_words[:5])}\n"
        
        prompt += """
è¯·æ ¹æ®ä»¥ä¸Šç‰¹å¾ï¼Œç”¨ç›¸ä¼¼çš„è¯­æ°”å’Œé£æ ¼å›å¤ã€‚ä¿æŒè‡ªç„¶ï¼Œä¸è¦åˆ»æ„æ¨¡ä»¿ã€‚
"""
        
        return prompt
    
    def _build_context(self, messages: List[Message]) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡"""
        if not messages:
            return "æš‚æ— ç›¸å…³ä¸Šä¸‹æ–‡"
        
        context_parts = []
        for msg in messages[:5]:  # æœ€å¤š5æ¡ç›¸å…³æ¶ˆæ¯
            timestamp = msg.timestamp.strftime("%Y-%m-%d %H:%M")
            context_parts.append(f"[{timestamp}] {msg.sender}: {msg.content}")
        
        return "\n".join(context_parts)
    
    async def analyze_conversation_patterns(
        self,
        persona_id: str,
        sample_size: int = 100
    ) -> Dict[str, Any]:
        """åˆ†æå¯¹è¯æ¨¡å¼"""
        try:
            # è·å–æ ·æœ¬æ¶ˆæ¯
            messages = await Message.find(
                {"persona_id": PydanticObjectId(persona_id)}
            ).sort("-timestamp").limit(sample_size).to_list()
            
            if not messages:
                return {}
            
            # åˆ†ææ¨¡å¼
            patterns = {
                "response_patterns": self._analyze_response_patterns(messages),
                "topic_transitions": self._analyze_topic_transitions(messages),
                "emotional_patterns": self._analyze_emotional_patterns(messages),
                "time_patterns": self._analyze_time_patterns(messages)
            }
            
            return patterns
            
        except Exception as e:
            logger.error(f"åˆ†æå¯¹è¯æ¨¡å¼å¤±è´¥: {str(e)}")
            return {}
    
    def _analyze_response_patterns(self, messages: List[Message]) -> Dict[str, Any]:
        """åˆ†æå›å¤æ¨¡å¼"""
        # ç®€åŒ–å®ç°
        total_length = sum(len(m.content) for m in messages)
        avg_length = total_length / len(messages) if messages else 0
        
        # åˆ†æå›å¤é€Ÿåº¦ï¼ˆå‡è®¾è¿ç»­æ¶ˆæ¯ï¼‰
        response_times = []
        for i in range(1, len(messages)):
            if messages[i].sender != messages[i-1].sender:
                time_diff = (messages[i-1].timestamp - messages[i].timestamp).total_seconds()
                if 0 < time_diff < 3600:  # 1å°æ—¶å†…çš„å›å¤
                    response_times.append(time_diff)
        
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0
        
        return {
            "average_message_length": avg_length,
            "average_response_time_seconds": avg_response_time,
            "message_count": len(messages)
        }
    
    def _analyze_topic_transitions(self, messages: List[Message]) -> List[str]:
        """åˆ†æè¯é¢˜è½¬æ¢"""
        # ç®€åŒ–å®ç°ï¼šè¯†åˆ«é—®å¥
        topics = []
        for msg in messages:
            if "ï¼Ÿ" in msg.content or "?" in msg.content:
                topics.append(msg.content[:20] + "...")
        return topics[:5]  # è¿”å›å‰5ä¸ªè¯é¢˜
    
    def _analyze_emotional_patterns(self, messages: List[Message]) -> Dict[str, float]:
        """åˆ†ææƒ…æ„Ÿæ¨¡å¼"""
        # ç®€åŒ–å®ç°ï¼šåŸºäºå…³é”®è¯
        emotions = {
            "positive": 0,
            "negative": 0,
            "neutral": 0
        }
        
        positive_words = ["å¥½", "å“ˆå“ˆ", "å¼€å¿ƒ", "å–œæ¬¢", "æ£’", "ğŸ˜Š", "ğŸ˜„", "â¤ï¸"]
        negative_words = ["ä¸", "éš¾è¿‡", "ç”Ÿæ°”", "è®¨åŒ", "çƒ¦", "ğŸ˜”", "ğŸ˜¢", "ğŸ˜¡"]
        
        for msg in messages:
            content = msg.content.lower()
            has_positive = any(word in content for word in positive_words)
            has_negative = any(word in content for word in negative_words)
            
            if has_positive and not has_negative:
                emotions["positive"] += 1
            elif has_negative and not has_positive:
                emotions["negative"] += 1
            else:
                emotions["neutral"] += 1
        
        # è½¬æ¢ä¸ºæ¯”ä¾‹
        total = sum(emotions.values())
        if total > 0:
            for key in emotions:
                emotions[key] = emotions[key] / total
        
        return emotions
    
    def _analyze_time_patterns(self, messages: List[Message]) -> Dict[str, Any]:
        """åˆ†ææ—¶é—´æ¨¡å¼"""
        # æ´»è·ƒæ—¶é—´æ®µåˆ†æ
        hour_distribution = {}
        for msg in messages:
            hour = msg.timestamp.hour
            hour_distribution[hour] = hour_distribution.get(hour, 0) + 1
        
        # æ‰¾å‡ºæœ€æ´»è·ƒçš„æ—¶é—´æ®µ
        if hour_distribution:
            peak_hour = max(hour_distribution, key=hour_distribution.get)
            peak_period = f"{peak_hour}:00-{(peak_hour+1)%24}:00"
        else:
            peak_period = "æœªçŸ¥"
        
        return {
            "peak_activity_period": peak_period,
            "hour_distribution": hour_distribution
        }