"""
Hybrid RAG æ¶æ„å®ç°
ä¸“é—¨é’ˆå¯¹äººæ ¼æ¨¡æ‹Ÿåœºæ™¯ä¼˜åŒ–
"""

from typing import List, Dict, Tuple
import numpy as np
from dataclasses import dataclass
from enum import Enum

class RetrievalStrategy(Enum):
    SEMANTIC = "semantic"          # è¯­ä¹‰ç›¸ä¼¼
    KEYWORD = "keyword"            # å…³é”®è¯åŒ¹é…
    TEMPORAL = "temporal"          # æ—¶é—´ç›¸å…³
    EMOTIONAL = "emotional"        # æƒ…ç»ªç›¸ä¼¼
    CONVERSATIONAL = "conversational"  # å¯¹è¯æ¨¡å¼

@dataclass
class Message:
    content: str
    timestamp: str
    sender: str
    context: List[str]  # å‰å‡ æ¡æ¶ˆæ¯
    emotion: str        # æƒ…ç»ªæ ‡ç­¾
    topic: str          # è¯é¢˜æ ‡ç­¾

class HybridRAGPersonality:
    """
    æ··åˆRAGç³»ç»Ÿï¼Œä¸“é—¨ç”¨äºäººæ ¼æ¨¡æ‹Ÿ
    """
    
    def __init__(self):
        self.vector_store = None  # å‘é‡æ•°æ®åº“
        self.keyword_index = {}   # å…³é”®è¯ç´¢å¼•
        self.pattern_bank = {}    # å¯¹è¯æ¨¡å¼åº“
        self.style_profile = {}   # é£æ ¼ç‰¹å¾
        
    def build_index(self, chat_history: List[Message]):
        """æ„å»ºå¤šç»´åº¦ç´¢å¼•"""
        
        # 1. å‘é‡ç´¢å¼• - è¯­ä¹‰ç›¸ä¼¼åº¦
        self._build_semantic_index(chat_history)
        
        # 2. å…³é”®è¯ç´¢å¼• - å¿«é€ŸåŒ¹é…å£å¤´ç¦…
        self._build_keyword_index(chat_history)
        
        # 3. å¯¹è¯æ¨¡å¼ç´¢å¼• - é—®ç­”æ¨¡å¼
        self._build_pattern_index(chat_history)
        
        # 4. æƒ…ç»ªç´¢å¼• - æƒ…ç»ªå“åº”æ¨¡å¼
        self._build_emotion_index(chat_history)
        
        # 5. æ—¶åºç´¢å¼• - å¯¹è¯èŠ‚å¥
        self._build_temporal_index(chat_history)
    
    def retrieve(self, query: str, context: List[str] = None) -> List[Message]:
        """
        æ··åˆæ£€ç´¢ç­–ç•¥
        """
        candidates = []
        
        # 1. è¯­ä¹‰æ£€ç´¢ - æ‰¾ç›¸ä¼¼è¯é¢˜ (æƒé‡ 40%)
        semantic_results = self._semantic_search(query, top_k=20)
        candidates.extend([(msg, 0.4, 'semantic') for msg in semantic_results])
        
        # 2. å…³é”®è¯æ£€ç´¢ - åŒ¹é…ç‰¹å®šç”¨è¯­ (æƒé‡ 20%)
        keyword_results = self._keyword_search(query, top_k=10)
        candidates.extend([(msg, 0.2, 'keyword') for msg in keyword_results])
        
        # 3. å¯¹è¯æ¨¡å¼æ£€ç´¢ - åŒ¹é…é—®ç­”æ¨¡å¼ (æƒé‡ 20%)
        if self._is_question(query):
            pattern_results = self._pattern_search('question_response', top_k=10)
            candidates.extend([(msg, 0.2, 'pattern') for msg in pattern_results])
        
        # 4. æƒ…ç»ªåŒ¹é… - æƒ…ç»ªä¸€è‡´æ€§ (æƒé‡ 10%)
        emotion = self._detect_emotion(query)
        emotion_results = self._emotion_search(emotion, top_k=5)
        candidates.extend([(msg, 0.1, 'emotion') for msg in emotion_results])
        
        # 5. ä¸Šä¸‹æ–‡è¿è´¯ - è€ƒè™‘å¯¹è¯æµç¨‹ (æƒé‡ 10%)
        if context:
            context_results = self._context_search(context, top_k=5)
            candidates.extend([(msg, 0.1, 'context') for msg in context_results])
        
        # é‡æ’åºå’Œå»é‡
        return self._rerank_and_dedupe(candidates)
    
    def generate_response(self, query: str, retrieved_messages: List[Message]) -> str:
        """
        åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆå›å¤
        """
        # 1. æå–é£æ ¼ç‰¹å¾
        style_features = self._extract_style_features(retrieved_messages)
        
        # 2. æ„å»ºå°‘æ ·æœ¬ç¤ºä¾‹
        few_shot_examples = self._select_diverse_examples(retrieved_messages, n=5)
        
        # 3. ç”Ÿæˆæç¤ºè¯
        prompt = self._build_generation_prompt(
            query=query,
            style=style_features,
            examples=few_shot_examples,
            personality=self.style_profile
        )
        
        # 4. è°ƒç”¨LLMç”Ÿæˆ
        response = self._call_llm(prompt)
        
        # 5. åå¤„ç† - ç¡®ä¿é£æ ¼ä¸€è‡´
        return self._post_process(response, style_features)
    
    def _build_semantic_index(self, messages: List[Message]):
        """æ„å»ºè¯­ä¹‰å‘é‡ç´¢å¼•"""
        # ä½¿ç”¨ sentence-transformers æˆ– OpenAI embeddings
        pass
    
    def _build_keyword_index(self, messages: List[Message]):
        """æ„å»ºå…³é”®è¯å€’æ’ç´¢å¼•"""
        for msg in messages:
            # æå–å…³é”®è¯å’Œå£å¤´ç¦…
            keywords = self._extract_keywords(msg.content)
            for keyword in keywords:
                if keyword not in self.keyword_index:
                    self.keyword_index[keyword] = []
                self.keyword_index[keyword].append(msg)
    
    def _build_pattern_index(self, messages: List[Message]):
        """æ„å»ºå¯¹è¯æ¨¡å¼ç´¢å¼•"""
        patterns = {
            'greeting': [],           # æ‰“æ‹›å‘¼
            'question_response': [],  # é—®ç­”
            'emotion_expression': [], # æƒ…ç»ªè¡¨è¾¾
            'topic_transition': [],   # è¯é¢˜è½¬æ¢
            'goodbye': []            # å‘Šåˆ«
        }
        
        for i, msg in enumerate(messages):
            pattern_type = self._classify_pattern(msg, messages[i-1] if i > 0 else None)
            patterns[pattern_type].append(msg)
        
        self.pattern_bank = patterns
    
    def _extract_style_features(self, messages: List[Message]) -> Dict:
        """æå–é£æ ¼ç‰¹å¾"""
        return {
            'avg_length': np.mean([len(m.content) for m in messages]),
            'emoji_usage': self._calculate_emoji_ratio(messages),
            'punctuation_style': self._analyze_punctuation(messages),
            'sentence_endings': self._common_endings(messages),
            'response_delay': self._avg_response_time(messages)
        }
    
    def _build_generation_prompt(self, query, style, examples, personality):
        """æ„å»ºç”Ÿæˆæç¤ºè¯"""
        prompt = f"""ä½ éœ€è¦æ¨¡ä»¿ä¸€ä¸ªç‰¹å®šçš„äººè¿›è¡Œå¯¹è¯ã€‚

## äººæ ¼ç‰¹å¾
- å¹³å‡æ¶ˆæ¯é•¿åº¦: {style['avg_length']:.0f}å­—
- è¡¨æƒ…ä½¿ç”¨é¢‘ç‡: {style['emoji_usage']:.2%}
- æ ‡ç‚¹é£æ ¼: {style['punctuation_style']}
- å¸¸è§å¥å°¾: {', '.join(style['sentence_endings'])}

## å¯¹è¯ç¤ºä¾‹
"""
        for ex in examples:
            prompt += f"ç”¨æˆ·: {ex.context[-1] if ex.context else '(å¼€å§‹å¯¹è¯)'}\n"
            prompt += f"å›å¤: {ex.content}\n\n"
        
        prompt += f"""## å½“å‰å¯¹è¯
ç”¨æˆ·: {query}
è¯·ç”¨ä¸Šè¿°é£æ ¼å›å¤ï¼Œä¿æŒäººæ ¼ä¸€è‡´æ€§ã€‚ä¸è¦è§£é‡Šï¼Œç›´æ¥å›å¤ã€‚"""
        
        return prompt
    
    def _rerank_and_dedupe(self, candidates: List[Tuple[Message, float, str]]) -> List[Message]:
        """é‡æ’åºå’Œå»é‡"""
        # æŒ‰ç»¼åˆå¾—åˆ†æ’åº
        seen = set()
        results = []
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        message_scores = {}
        for msg, weight, source in candidates:
            if msg.content not in message_scores:
                message_scores[msg.content] = {
                    'message': msg,
                    'score': 0,
                    'sources': []
                }
            message_scores[msg.content]['score'] += weight
            message_scores[msg.content]['sources'].append(source)
        
        # æ’åºå¹¶è¿”å›
        sorted_messages = sorted(
            message_scores.values(), 
            key=lambda x: x['score'], 
            reverse=True
        )
        
        return [item['message'] for item in sorted_messages[:10]]
    
    # è¾…åŠ©æ–¹æ³•
    def _is_question(self, text: str) -> bool:
        question_markers = ['ï¼Ÿ', '?', 'å—', 'å‘¢', 'ä¹ˆ', 'å“ª', 'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ']
        return any(marker in text for marker in question_markers)
    
    def _detect_emotion(self, text: str) -> str:
        # ç®€åŒ–çš„æƒ…ç»ªæ£€æµ‹
        if any(word in text for word in ['å¼€å¿ƒ', 'é«˜å…´', 'å“ˆå“ˆ', 'ğŸ˜Š', 'ğŸ˜„']):
            return 'positive'
        elif any(word in text for word in ['éš¾è¿‡', 'ä¼¤å¿ƒ', 'å”‰', 'ğŸ˜”', 'ğŸ˜¢']):
            return 'negative'
        return 'neutral'
    
    def _extract_keywords(self, text: str) -> List[str]:
        # æå–å…³é”®è¯å’Œå£å¤´ç¦…
        import jieba
        words = jieba.lcut(text)
        # è¿‡æ»¤åœç”¨è¯ï¼Œä¿ç•™ç‰¹å¾è¯
        return [w for w in words if len(w) > 1]

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–ç³»ç»Ÿ
    rag_system = HybridRAGPersonality()
    
    # æ„å»ºç´¢å¼•
    chat_history = [
        Message(
            content="å“ˆå“ˆå“ˆå“ˆå¤ªæç¬‘äº†",
            timestamp="2024-01-01 10:00",
            sender="friend",
            context=["åˆ†äº«äº†ä¸€ä¸ªè§†é¢‘"],
            emotion="positive",
            topic="entertainment"
        ),
        # ... æ›´å¤šå†å²æ¶ˆæ¯
    ]
    
    rag_system.build_index(chat_history)
    
    # ç”Ÿæˆå›å¤
    user_query = "ä»Šå¤©å¥½ç´¯å•Š"
    retrieved = rag_system.retrieve(user_query, context=["åˆšä¸‹ç­"])
    response = rag_system.generate_response(user_query, retrieved)
    
    print(f"æ¨¡æ‹Ÿå›å¤: {response}")